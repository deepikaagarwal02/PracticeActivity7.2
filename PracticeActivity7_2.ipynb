{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "Link to Github Repo: <https://github.com/deepikaagarwal02/PracticeActivity7.2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Practice Activity 7.2\n",
        "author: \"Deepika Agarwal\"\n",
        "format:\n",
        "  html:\n",
        "    embed-resources: true\n",
        "echo: true\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nMs1ABlf8cFu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import make_column_selector, ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from plotnine import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "W-vK3AEk7Ken",
        "outputId": "3c5a86b2-4ab6-463d-8be1-3b866751fe85"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>PID</th>\n",
              "      <th>MS SubClass</th>\n",
              "      <th>MS Zoning</th>\n",
              "      <th>Lot Frontage</th>\n",
              "      <th>Lot Area</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>Lot Shape</th>\n",
              "      <th>Land Contour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>Lot Config</th>\n",
              "      <th>Land Slope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition 1</th>\n",
              "      <th>Condition 2</th>\n",
              "      <th>Bldg Type</th>\n",
              "      <th>House Style</th>\n",
              "      <th>Overall Qual</th>\n",
              "      <th>Overall Cond</th>\n",
              "      <th>Year Built</th>\n",
              "      <th>Year Remod/Add</th>\n",
              "      <th>Roof Style</th>\n",
              "      <th>Roof Matl</th>\n",
              "      <th>Exterior 1st</th>\n",
              "      <th>Exterior 2nd</th>\n",
              "      <th>Mas Vnr Type</th>\n",
              "      <th>Mas Vnr Area</th>\n",
              "      <th>Exter Qual</th>\n",
              "      <th>Exter Cond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>Bsmt Qual</th>\n",
              "      <th>Bsmt Cond</th>\n",
              "      <th>Bsmt Exposure</th>\n",
              "      <th>BsmtFin Type 1</th>\n",
              "      <th>BsmtFin SF 1</th>\n",
              "      <th>BsmtFin Type 2</th>\n",
              "      <th>BsmtFin SF 2</th>\n",
              "      <th>Bsmt Unf SF</th>\n",
              "      <th>Total Bsmt SF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>Heating QC</th>\n",
              "      <th>Central Air</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1st Flr SF</th>\n",
              "      <th>2nd Flr SF</th>\n",
              "      <th>Low Qual Fin SF</th>\n",
              "      <th>Gr Liv Area</th>\n",
              "      <th>Bsmt Full Bath</th>\n",
              "      <th>Bsmt Half Bath</th>\n",
              "      <th>Full Bath</th>\n",
              "      <th>Half Bath</th>\n",
              "      <th>Bedroom AbvGr</th>\n",
              "      <th>Kitchen AbvGr</th>\n",
              "      <th>Kitchen Qual</th>\n",
              "      <th>TotRms AbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>Fireplace Qu</th>\n",
              "      <th>Garage Type</th>\n",
              "      <th>Garage Yr Blt</th>\n",
              "      <th>Garage Finish</th>\n",
              "      <th>Garage Cars</th>\n",
              "      <th>Garage Area</th>\n",
              "      <th>Garage Qual</th>\n",
              "      <th>Garage Cond</th>\n",
              "      <th>Paved Drive</th>\n",
              "      <th>Wood Deck SF</th>\n",
              "      <th>Open Porch SF</th>\n",
              "      <th>Enclosed Porch</th>\n",
              "      <th>3Ssn Porch</th>\n",
              "      <th>Screen Porch</th>\n",
              "      <th>Pool Area</th>\n",
              "      <th>Pool QC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>Misc Feature</th>\n",
              "      <th>Misc Val</th>\n",
              "      <th>Mo Sold</th>\n",
              "      <th>Yr Sold</th>\n",
              "      <th>Sale Type</th>\n",
              "      <th>Sale Condition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>526301100</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>141.0</td>\n",
              "      <td>31770</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>Hip</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>Plywood</td>\n",
              "      <td>Stone</td>\n",
              "      <td>112.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Gd</td>\n",
              "      <td>BLQ</td>\n",
              "      <td>639.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>441.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Fa</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1656</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1656</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>2</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1960.0</td>\n",
              "      <td>Fin</td>\n",
              "      <td>2.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>P</td>\n",
              "      <td>210</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>215000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>526350040</td>\n",
              "      <td>20</td>\n",
              "      <td>RH</td>\n",
              "      <td>80.0</td>\n",
              "      <td>11622</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1961</td>\n",
              "      <td>1961</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>Rec</td>\n",
              "      <td>468.0</td>\n",
              "      <td>LwQ</td>\n",
              "      <td>144.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>882.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>896</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>896</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>5</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1961.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1.0</td>\n",
              "      <td>730.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>105000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>526351010</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>81.0</td>\n",
              "      <td>14267</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1958</td>\n",
              "      <td>1958</td>\n",
              "      <td>Hip</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>108.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>923.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>1329.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1329</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1329</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1958.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>393</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gar2</td>\n",
              "      <td>12500</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>172000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>526353030</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>93.0</td>\n",
              "      <td>11160</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1968</td>\n",
              "      <td>1968</td>\n",
              "      <td>Hip</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1045.0</td>\n",
              "      <td>2110.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>2110</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2110</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Ex</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>2</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1968.0</td>\n",
              "      <td>Fin</td>\n",
              "      <td>2.0</td>\n",
              "      <td>522.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>244000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>527105010</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>74.0</td>\n",
              "      <td>13830</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Gilbert</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1997</td>\n",
              "      <td>1998</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>791.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>928.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>928</td>\n",
              "      <td>701</td>\n",
              "      <td>0</td>\n",
              "      <td>1629</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>Fin</td>\n",
              "      <td>2.0</td>\n",
              "      <td>482.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>212</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>189900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Order        PID  MS SubClass MS Zoning  ...  Yr Sold  Sale Type Sale Condition SalePrice\n",
              "0      1  526301100           20        RL  ...     2010        WD          Normal    215000\n",
              "1      2  526350040           20        RH  ...     2010        WD          Normal    105000\n",
              "2      3  526351010           20        RL  ...     2010        WD          Normal    172000\n",
              "3      4  526353030           20        RL  ...     2010        WD          Normal    244000\n",
              "4      5  527105010           60        RL  ...     2010        WD          Normal    189900\n",
              "\n",
              "[5 rows x 82 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ames = pd.read_csv(\"AmesHousing.csv\")\n",
        "ames.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dAGtwcWH9JMX"
      },
      "outputs": [],
      "source": [
        "# Get rid of columns with NaN values more than 100\n",
        "good_cols = ames.isna().sum() < 100\n",
        "ames = ames.loc[:,good_cols]\n",
        "\n",
        "# Drop other NAs\n",
        "ames = ames.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iQ-4pv9b9P39"
      },
      "outputs": [],
      "source": [
        "X = ames.drop([\"SalePrice\", \"Order\", \"PID\"], axis = 1)\n",
        "y = ames[\"SalePrice\"]"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "4wO2_X4eEX8O"
      },
      "source": [
        "# Practice Activity: 1\n",
        "Make a pipeline that uses all the variables in the Ames dataset, and then fits Ridge Regression with λ = 1\n",
        ".\n",
        "\n",
        "Cross-validate this pipeline and compare the results to the ordinary linear regression.\n",
        "\n",
        "Then fit the model on the whole dataset and get the coefficients. Make a plot of these coefficients compared to the ones from ordinary linear regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zaEpHVXNsp-R"
      },
      "outputs": [],
      "source": [
        "ct = ColumnTransformer(\n",
        "  [\n",
        "    (\"dummify\",\n",
        "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
        "    make_column_selector(dtype_include=object)),\n",
        "    (\"standardize\",\n",
        "    StandardScaler(),\n",
        "    make_column_selector(dtype_include=np.number))\n",
        "  ],\n",
        "  remainder = \"passthrough\"\n",
        ").set_output(transform=\"pandas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hp1CSNAAspxp"
      },
      "outputs": [],
      "source": [
        "lr_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"linear_regression\", LinearRegression())]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9ylGZFe88Tc",
        "outputId": "2d8ffcdc-06bb-4631-9567-46a868a48351"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.8538898800207827)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_scores = cross_val_score(lr_pipeline, X, y, cv = 5, scoring = 'r2')\n",
        "lr_scores.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uCgTMl9fvk2_"
      },
      "outputs": [],
      "source": [
        "lr_pipeline_fitted = lr_pipeline.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r5DaTOpr9Uk9"
      },
      "outputs": [],
      "source": [
        "ridge_pipeline = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"ridge_regression\", Ridge(alpha=1))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFgTqeiT9ZIR",
        "outputId": "28e3bd8c-fbaf-4892-d841-0e8de41490d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.8619316345217335)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ridge_scores = cross_val_score(ridge_pipeline, X, y, cv = 5, scoring = 'r2')\n",
        "ridge_scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdDrzu6vBvDi"
      },
      "source": [
        "Analysis: Ridge Regression performs better than Linear Regression because it has a higher Rsquare value. This means Ridge explains more variance in the data and generalizes better. The improvement happens because Ridge uses L2 regularization which reduces overfitting by shrinking large coefficients and stabilizing the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wpYveSpW9fTj"
      },
      "outputs": [],
      "source": [
        "ridge_pipeline_fitted = ridge_pipeline.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pvoQrN7B-P9o"
      },
      "outputs": [],
      "source": [
        "coef_compare = pd.DataFrame()\n",
        "\n",
        "coef_compare[\"lr\"] = lr_pipeline_fitted.named_steps['linear_regression'].coef_\n",
        "coef_compare[\"ridge\"] = ridge_pipeline_fitted.named_steps['ridge_regression'].coef_\n",
        "coef_compare[\"diff\"] = coef_compare[\"lr\"] - coef_compare[\"ridge\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Yj_dvfTt-Zfh",
        "outputId": "598cc727-8cd0-47c1-dcfc-e5eb8b1ef400"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lr</th>\n",
              "      <th>ridge</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>-559653.342134</td>\n",
              "      <td>-233156.089658</td>\n",
              "      <td>-326497.252476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>-113384.181772</td>\n",
              "      <td>-77996.160321</td>\n",
              "      <td>-35388.021451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>-33825.937758</td>\n",
              "      <td>-16633.220977</td>\n",
              "      <td>-17192.716782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>-20968.886474</td>\n",
              "      <td>-6399.635769</td>\n",
              "      <td>-14569.250704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>-17416.886121</td>\n",
              "      <td>-6826.403541</td>\n",
              "      <td>-10590.482579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>55399.766568</td>\n",
              "      <td>16828.505080</td>\n",
              "      <td>38571.261487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>64910.291903</td>\n",
              "      <td>24567.527777</td>\n",
              "      <td>40342.764126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>127054.304996</td>\n",
              "      <td>66530.685838</td>\n",
              "      <td>60523.619159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>109059.255835</td>\n",
              "      <td>28387.663156</td>\n",
              "      <td>80671.592679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>119504.966230</td>\n",
              "      <td>32582.552859</td>\n",
              "      <td>86922.413371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>254 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                lr          ridge           diff\n",
              "91  -559653.342134 -233156.089658 -326497.252476\n",
              "68  -113384.181772  -77996.160321  -35388.021451\n",
              "106  -33825.937758  -16633.220977  -17192.716782\n",
              "85   -20968.886474   -6399.635769  -14569.250704\n",
              "124  -17416.886121   -6826.403541  -10590.482579\n",
              "..             ...            ...            ...\n",
              "95    55399.766568   16828.505080   38571.261487\n",
              "69    64910.291903   24567.527777   40342.764126\n",
              "37   127054.304996   66530.685838   60523.619159\n",
              "94   109059.255835   28387.663156   80671.592679\n",
              "93   119504.966230   32582.552859   86922.413371\n",
              "\n",
              "[254 rows x 3 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "coef_compare.sort_values(by = \"diff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "zrTCYyeu1JzG",
        "outputId": "58aeb954-13b0-45fc-8ed2-1029585d5328"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot = (\n",
        "    ggplot(coef_compare, aes(x='lr', y='ridge')) +\n",
        "    geom_abline(intercept=0, slope=1, linetype='dashed', color='red') +\n",
        "    geom_point(color='blue', size=3) +\n",
        "    labs(\n",
        "        title='Comparison of Coefficients',\n",
        "        x='Linear Regression Coefficients',\n",
        "        y='Ridge Regression Coefficients'\n",
        "    ) +\n",
        "    theme_bw()\n",
        ")\n",
        "\n",
        "plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7p_6USb_9w2"
      },
      "source": [
        "Analysis: The plot shows that Ridge Regression coefficients are smaller than those from Linear Regression. This happens because Ridge uses L2 regularization, which shrinks large coefficients toward zero, making the model more stable and less prone to overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDnLh_NRE7zB"
      },
      "source": [
        "# Practice Activity: 2\n",
        "\n",
        "Using the same pipeline as previously, perform tuning on λ.\n",
        "\n",
        "You should always try λ values on a log scale; that is, don’t use [1,2,3,4]; instead use something like [0.001, 0.01, 0.1, 1, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2bnW7Vq1IC8Q"
      },
      "outputs": [],
      "source": [
        "ridge_pipeline_1 = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"ridge_regression\", Ridge())]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "alphas = {'ridge_regression__alpha': np.array([100, 10, 1, 0.1, 0.01])}\n",
        "\n",
        "gscv_ridge = GridSearchCV(ridge_pipeline_1, param_grid=alphas, cv = 5, scoring='r2', n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2mnlVnmbKBUM"
      },
      "outputs": [],
      "source": [
        "gscv_fitted_ridge = gscv_ridge.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "I2RoiAcVKBUM",
        "outputId": "df65aa58-ba2b-42c7-de63-bd25b47099f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_ridge_regression__alpha</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.039964</td>\n",
              "      <td>0.011010</td>\n",
              "      <td>0.015543</td>\n",
              "      <td>0.004134</td>\n",
              "      <td>100.00</td>\n",
              "      <td>{'ridge_regression__alpha': 100.0}</td>\n",
              "      <td>0.887765</td>\n",
              "      <td>0.921979</td>\n",
              "      <td>0.793420</td>\n",
              "      <td>0.772149</td>\n",
              "      <td>0.913554</td>\n",
              "      <td>0.857773</td>\n",
              "      <td>0.062620</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.042362</td>\n",
              "      <td>0.015357</td>\n",
              "      <td>0.015323</td>\n",
              "      <td>0.004048</td>\n",
              "      <td>10.00</td>\n",
              "      <td>{'ridge_regression__alpha': 10.0}</td>\n",
              "      <td>0.897762</td>\n",
              "      <td>0.920812</td>\n",
              "      <td>0.800572</td>\n",
              "      <td>0.787120</td>\n",
              "      <td>0.915095</td>\n",
              "      <td>0.864272</td>\n",
              "      <td>0.058157</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.037822</td>\n",
              "      <td>0.008132</td>\n",
              "      <td>0.008497</td>\n",
              "      <td>0.002116</td>\n",
              "      <td>1.00</td>\n",
              "      <td>{'ridge_regression__alpha': 1.0}</td>\n",
              "      <td>0.898158</td>\n",
              "      <td>0.917440</td>\n",
              "      <td>0.794936</td>\n",
              "      <td>0.785226</td>\n",
              "      <td>0.913898</td>\n",
              "      <td>0.861932</td>\n",
              "      <td>0.059104</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.036205</td>\n",
              "      <td>0.007892</td>\n",
              "      <td>0.012790</td>\n",
              "      <td>0.005092</td>\n",
              "      <td>0.10</td>\n",
              "      <td>{'ridge_regression__alpha': 0.1}</td>\n",
              "      <td>0.897744</td>\n",
              "      <td>0.912306</td>\n",
              "      <td>0.790110</td>\n",
              "      <td>0.775764</td>\n",
              "      <td>0.905587</td>\n",
              "      <td>0.856302</td>\n",
              "      <td>0.060250</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.025582</td>\n",
              "      <td>0.002610</td>\n",
              "      <td>0.007545</td>\n",
              "      <td>0.000976</td>\n",
              "      <td>0.01</td>\n",
              "      <td>{'ridge_regression__alpha': 0.01}</td>\n",
              "      <td>0.897343</td>\n",
              "      <td>0.910614</td>\n",
              "      <td>0.789126</td>\n",
              "      <td>0.772532</td>\n",
              "      <td>0.901317</td>\n",
              "      <td>0.854186</td>\n",
              "      <td>0.060280</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  ...  mean_test_score  std_test_score rank_test_score\n",
              "0       0.039964      0.011010         0.015543  ...         0.857773        0.062620               3\n",
              "1       0.042362      0.015357         0.015323  ...         0.864272        0.058157               1\n",
              "2       0.037822      0.008132         0.008497  ...         0.861932        0.059104               2\n",
              "3       0.036205      0.007892         0.012790  ...         0.856302        0.060250               4\n",
              "4       0.025582      0.002610         0.007545  ...         0.854186        0.060280               5\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cv_results_ridge = pd.DataFrame(gscv_fitted_ridge.cv_results_)\n",
        "\n",
        "df_cv_results_ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLxJT9Cu24rr",
        "outputId": "3f9a4712-9457-4ef1-b13a-d10be6746bb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ridge_regression__alpha': np.float64(10.0)}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gscv_fitted_ridge.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOvzil5h3Bsc",
        "outputId": "255c90fe-aa73-4db8-c227-a12f79be7dff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.8642722110166746)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gscv_fitted_ridge.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q3NvXrnFLHO"
      },
      "source": [
        "# Practice Activity: 3\n",
        "\n",
        "Create a LASSO pipeline, and tune λ.\n",
        "\n",
        "Fit your best model on the full Ames data, and compare the coefficients to Ridge and OLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pyCcFAhL4CIM"
      },
      "outputs": [],
      "source": [
        "lasso_pipeline_1 = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"lasso_regression\", Lasso())]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "alphas = {'lasso_regression__alpha': np.array([100, 10, 1, 0.1, 0.01])}\n",
        "\n",
        "gscv_lasso = GridSearchCV(lasso_pipeline_1, param_grid=alphas, cv = 5, scoring='r2', n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NSfNFUvS4CIN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.323e+10, tolerance: 1.477e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.236e+11, tolerance: 1.348e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+11, tolerance: 1.463e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e+11, tolerance: 1.474e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.557e+11, tolerance: 1.477e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+11, tolerance: 1.407e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+11, tolerance: 1.348e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+11, tolerance: 1.474e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+11, tolerance: 1.463e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e+11, tolerance: 1.407e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+11, tolerance: 1.477e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "gscv_fitted_lasso = gscv_lasso.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "6eSH_VHl4CIN",
        "outputId": "9723b972-2d96-4f97-a98d-28068cc651bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_lasso_regression__alpha</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.134419</td>\n",
              "      <td>0.021002</td>\n",
              "      <td>0.010546</td>\n",
              "      <td>0.001202</td>\n",
              "      <td>100.00</td>\n",
              "      <td>{'lasso_regression__alpha': 100.0}</td>\n",
              "      <td>0.901800</td>\n",
              "      <td>0.924433</td>\n",
              "      <td>0.805390</td>\n",
              "      <td>0.783485</td>\n",
              "      <td>0.919547</td>\n",
              "      <td>0.866931</td>\n",
              "      <td>0.060069</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.208009</td>\n",
              "      <td>0.104578</td>\n",
              "      <td>0.017240</td>\n",
              "      <td>0.006045</td>\n",
              "      <td>10.00</td>\n",
              "      <td>{'lasso_regression__alpha': 10.0}</td>\n",
              "      <td>0.900776</td>\n",
              "      <td>0.915067</td>\n",
              "      <td>0.801420</td>\n",
              "      <td>0.776649</td>\n",
              "      <td>0.909250</td>\n",
              "      <td>0.860632</td>\n",
              "      <td>0.059157</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.872371</td>\n",
              "      <td>1.143296</td>\n",
              "      <td>0.129808</td>\n",
              "      <td>0.059128</td>\n",
              "      <td>1.00</td>\n",
              "      <td>{'lasso_regression__alpha': 1.0}</td>\n",
              "      <td>0.897744</td>\n",
              "      <td>0.910938</td>\n",
              "      <td>0.796918</td>\n",
              "      <td>0.774262</td>\n",
              "      <td>0.905899</td>\n",
              "      <td>0.857152</td>\n",
              "      <td>0.059018</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.319786</td>\n",
              "      <td>1.523368</td>\n",
              "      <td>0.279104</td>\n",
              "      <td>0.189817</td>\n",
              "      <td>0.10</td>\n",
              "      <td>{'lasso_regression__alpha': 0.1}</td>\n",
              "      <td>0.897258</td>\n",
              "      <td>0.910451</td>\n",
              "      <td>0.795951</td>\n",
              "      <td>0.774072</td>\n",
              "      <td>0.905360</td>\n",
              "      <td>0.856618</td>\n",
              "      <td>0.059025</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.188613</td>\n",
              "      <td>0.817850</td>\n",
              "      <td>0.276873</td>\n",
              "      <td>0.148460</td>\n",
              "      <td>0.01</td>\n",
              "      <td>{'lasso_regression__alpha': 0.01}</td>\n",
              "      <td>0.897206</td>\n",
              "      <td>0.910401</td>\n",
              "      <td>0.790859</td>\n",
              "      <td>0.774060</td>\n",
              "      <td>0.905502</td>\n",
              "      <td>0.855606</td>\n",
              "      <td>0.060107</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  ...  mean_test_score  std_test_score rank_test_score\n",
              "0       0.134419      0.021002         0.010546  ...         0.866931        0.060069               1\n",
              "1       0.208009      0.104578         0.017240  ...         0.860632        0.059157               2\n",
              "2       1.872371      1.143296         0.129808  ...         0.857152        0.059018               3\n",
              "3       6.319786      1.523368         0.279104  ...         0.856618        0.059025               4\n",
              "4       8.188613      0.817850         0.276873  ...         0.855606        0.060107               5\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cv_results_lasso= pd.DataFrame(gscv_fitted_lasso.cv_results_)\n",
        "\n",
        "df_cv_results_lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGTWRQ5E4CIO",
        "outputId": "93510aa2-d281-4947-8af4-030d2e9b00c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'lasso_regression__alpha': np.float64(100.0)}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gscv_fitted_lasso.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPO7WaiZ4CIO",
        "outputId": "aef4b2f5-dc8b-4cbe-c1a6-a9aaaf21502d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.8669311075511448)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gscv_fitted_lasso.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "uD7XohqU6Arm",
        "outputId": "85c5561a-bb11-4a84-9965-06a89aa5f9b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lr</th>\n",
              "      <th>ridge</th>\n",
              "      <th>lasso</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-4648.554959</td>\n",
              "      <td>-4906.494598</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1546.687999</td>\n",
              "      <td>2346.943135</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-7516.051924</td>\n",
              "      <td>-1229.177404</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7867.442231</td>\n",
              "      <td>4620.911891</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3774.440540</td>\n",
              "      <td>2204.285000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>2670.612233</td>\n",
              "      <td>3104.701760</td>\n",
              "      <td>2829.886060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>2776.215267</td>\n",
              "      <td>489.258612</td>\n",
              "      <td>791.915349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>-5139.727420</td>\n",
              "      <td>-4135.488058</td>\n",
              "      <td>-4328.443776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>-774.812417</td>\n",
              "      <td>-638.220273</td>\n",
              "      <td>-576.052919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>-613.063064</td>\n",
              "      <td>-977.427542</td>\n",
              "      <td>-767.372632</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>254 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              lr        ridge        lasso\n",
              "0   -4648.554959 -4906.494598    -0.000000\n",
              "1    1546.687999  2346.943135     0.000000\n",
              "2   -7516.051924 -1229.177404    -0.000000\n",
              "3    7867.442231  4620.911891     0.000000\n",
              "4    3774.440540  2204.285000     0.000000\n",
              "..           ...          ...          ...\n",
              "249  2670.612233  3104.701760  2829.886060\n",
              "250  2776.215267   489.258612   791.915349\n",
              "251 -5139.727420 -4135.488058 -4328.443776\n",
              "252  -774.812417  -638.220273  -576.052919\n",
              "253  -613.063064  -977.427542  -767.372632\n",
              "\n",
              "[254 rows x 3 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ridge_coef = gscv_fitted_ridge.best_estimator_.named_steps['ridge_regression'].coef_\n",
        "lasso_coef = gscv_fitted_lasso.best_estimator_.named_steps['lasso_regression'].coef_\n",
        "\n",
        "coef_df = pd.DataFrame()\n",
        "\n",
        "coef_df[\"lr\"] = lr_pipeline_fitted.named_steps['linear_regression'].coef_\n",
        "coef_df[\"ridge\"] = ridge_coef\n",
        "coef_df[\"lasso\"] = lasso_coef\n",
        "\n",
        "coef_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BsD9xg28HHT",
        "outputId": "93b6178f-5a6d-4359-b080-e7e2136747c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(163)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(coef_df[\"lasso\"] == 0).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0bnMaaj8KHv",
        "outputId": "49e47bb0-5688-4742-9e0f-9e1d44040608"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(coef_df[\"ridge\"] == 0).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sCryxQlDMcr"
      },
      "source": [
        "Anlaysis: The dataframe shows that Ridge coefficients are smaller than Linear Regression due to L2 regularization, which reduces overfitting. Lasso goes further with L1 regularization, setting 163 out of 254 coefficients to zero, effectively selecting key features and simplifying the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "sw0U7p_p8NfH",
        "outputId": "81f1a5af-98ca-4962-e5ff-f77bae50b92b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot = (\n",
        "    ggplot(coef_df, aes(x='ridge', y='lasso')) +\n",
        "    geom_point(color='red', size=3) +\n",
        "    labs(\n",
        "        title='Comparison of Coefficients',\n",
        "        x='Ridge Regression Coefficients',\n",
        "        y='Lasso Regression Coefficients'\n",
        "    ) +\n",
        "    theme_bw()\n",
        ")\n",
        "\n",
        "plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLQ0Zna-ERKy"
      },
      "source": [
        "Analysis: The plot shows that most of the Lasso coefficients are zero, while Ridge keeps small nonzero values. This means Lasso removes less important features to make the model simpler, while Ridge keeps all features but makes their values smaller."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SWsPvGpF1qd"
      },
      "source": [
        "# Practice Activity: 4\n",
        "Create an Elastic Net pipeline, and tune λ and α.\n",
        "\n",
        "Fit your best model on the full Ames data, and compare the coefficients to Ridge and OLS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "KiP_8oaXOb33"
      },
      "outputs": [],
      "source": [
        "elastic_pipeline_1 = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"elastic_net\", ElasticNet())]\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "param_grid = {\n",
        "    \"elastic_net__alpha\": [100, 10, 1, 0.1, 0.01],\n",
        "    \"elastic_net__l1_ratio\": np.arange(0.0, 1.2, 0.2),\n",
        "}\n",
        "\n",
        "gscv_elastic = GridSearchCV(elastic_pipeline_1, param_grid=param_grid, cv = 5, scoring='r2', n_jobs = -1, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slkM_hmxOb33",
        "outputId": "209b4236-606f-451e-c030-50fbc737a90e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.372e+12, tolerance: 1.348e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.960e+12, tolerance: 1.474e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.894e+12, tolerance: 1.463e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.630e+12, tolerance: 1.407e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.971e+12, tolerance: 1.477e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.468e+12, tolerance: 1.348e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.754e+12, tolerance: 1.463e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.545e+12, tolerance: 1.407e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.860e+12, tolerance: 1.474e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.857e+12, tolerance: 1.477e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.919e+12, tolerance: 1.348e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+12, tolerance: 1.474e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.790e+12, tolerance: 1.407e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.921e+12, tolerance: 1.463e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.074e+12, tolerance: 1.477e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.323e+10, tolerance: 1.477e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+12, tolerance: 1.348e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.783e+11, tolerance: 1.463e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+12, tolerance: 1.474e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.013e+11, tolerance: 1.407e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+12, tolerance: 1.477e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+11, tolerance: 1.463e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.236e+11, tolerance: 1.348e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e+11, tolerance: 1.474e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+11, tolerance: 1.407e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.782e+11, tolerance: 1.348e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.645e+11, tolerance: 1.474e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.557e+11, tolerance: 1.477e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.090e+11, tolerance: 1.463e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.465e+11, tolerance: 1.407e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.590e+11, tolerance: 1.477e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.280e+11, tolerance: 1.474e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.951e+11, tolerance: 1.348e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e+11, tolerance: 1.463e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e+11, tolerance: 1.407e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.144e+11, tolerance: 1.477e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.683e+11, tolerance: 1.348e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.467e+11, tolerance: 1.474e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.189e+11, tolerance: 1.463e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.534e+11, tolerance: 1.407e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.429e+11, tolerance: 1.477e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+11, tolerance: 1.474e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+11, tolerance: 1.348e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+11, tolerance: 1.463e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e+11, tolerance: 1.407e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+11, tolerance: 1.477e+09\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "gscv_fitted_elastic = gscv_elastic.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cBsi9jz6Ob33",
        "outputId": "b0a443b6-904d-4a9f-89ba-a2b09fa235b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_elastic_net__alpha</th>\n",
              "      <th>param_elastic_net__l1_ratio</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.099353</td>\n",
              "      <td>0.184961</td>\n",
              "      <td>0.078556</td>\n",
              "      <td>0.020863</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'elastic_net__alpha': 100, 'elastic_net__l1_r...</td>\n",
              "      <td>0.068602</td>\n",
              "      <td>0.114533</td>\n",
              "      <td>0.107924</td>\n",
              "      <td>0.102946</td>\n",
              "      <td>0.105640</td>\n",
              "      <td>0.099929</td>\n",
              "      <td>0.016126</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.735556</td>\n",
              "      <td>0.090153</td>\n",
              "      <td>0.098475</td>\n",
              "      <td>0.077092</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>{'elastic_net__alpha': 100, 'elastic_net__l1_r...</td>\n",
              "      <td>0.090762</td>\n",
              "      <td>0.139899</td>\n",
              "      <td>0.132094</td>\n",
              "      <td>0.125232</td>\n",
              "      <td>0.130752</td>\n",
              "      <td>0.123748</td>\n",
              "      <td>0.017145</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.482855</td>\n",
              "      <td>0.212672</td>\n",
              "      <td>0.126260</td>\n",
              "      <td>0.059934</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.4</td>\n",
              "      <td>{'elastic_net__alpha': 100, 'elastic_net__l1_r...</td>\n",
              "      <td>0.125392</td>\n",
              "      <td>0.179344</td>\n",
              "      <td>0.169608</td>\n",
              "      <td>0.159851</td>\n",
              "      <td>0.169794</td>\n",
              "      <td>0.160798</td>\n",
              "      <td>0.018745</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.441589</td>\n",
              "      <td>0.199112</td>\n",
              "      <td>0.113518</td>\n",
              "      <td>0.029247</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'elastic_net__alpha': 100, 'elastic_net__l1_r...</td>\n",
              "      <td>0.187065</td>\n",
              "      <td>0.248971</td>\n",
              "      <td>0.235584</td>\n",
              "      <td>0.220823</td>\n",
              "      <td>0.238682</td>\n",
              "      <td>0.226225</td>\n",
              "      <td>0.021554</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.218410</td>\n",
              "      <td>0.028490</td>\n",
              "      <td>0.084411</td>\n",
              "      <td>0.015165</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.8</td>\n",
              "      <td>{'elastic_net__alpha': 100, 'elastic_net__l1_r...</td>\n",
              "      <td>0.326931</td>\n",
              "      <td>0.403467</td>\n",
              "      <td>0.380581</td>\n",
              "      <td>0.355303</td>\n",
              "      <td>0.391397</td>\n",
              "      <td>0.371536</td>\n",
              "      <td>0.027382</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.985579</td>\n",
              "      <td>0.132381</td>\n",
              "      <td>0.072317</td>\n",
              "      <td>0.012869</td>\n",
              "      <td>100.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'elastic_net__alpha': 100, 'elastic_net__l1_r...</td>\n",
              "      <td>0.901800</td>\n",
              "      <td>0.924433</td>\n",
              "      <td>0.805390</td>\n",
              "      <td>0.783485</td>\n",
              "      <td>0.919547</td>\n",
              "      <td>0.866931</td>\n",
              "      <td>0.060069</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.819300</td>\n",
              "      <td>0.209461</td>\n",
              "      <td>0.068532</td>\n",
              "      <td>0.019165</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'elastic_net__alpha': 10, 'elastic_net__l1_ra...</td>\n",
              "      <td>0.492511</td>\n",
              "      <td>0.578344</td>\n",
              "      <td>0.541161</td>\n",
              "      <td>0.505391</td>\n",
              "      <td>0.563972</td>\n",
              "      <td>0.536276</td>\n",
              "      <td>0.032954</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.208285</td>\n",
              "      <td>0.020300</td>\n",
              "      <td>0.117551</td>\n",
              "      <td>0.045386</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>{'elastic_net__alpha': 10, 'elastic_net__l1_ra...</td>\n",
              "      <td>0.543978</td>\n",
              "      <td>0.630330</td>\n",
              "      <td>0.587613</td>\n",
              "      <td>0.549154</td>\n",
              "      <td>0.615216</td>\n",
              "      <td>0.585258</td>\n",
              "      <td>0.034473</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.255570</td>\n",
              "      <td>0.058557</td>\n",
              "      <td>0.070383</td>\n",
              "      <td>0.010436</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.4</td>\n",
              "      <td>{'elastic_net__alpha': 10, 'elastic_net__l1_ra...</td>\n",
              "      <td>0.605470</td>\n",
              "      <td>0.690470</td>\n",
              "      <td>0.640126</td>\n",
              "      <td>0.598959</td>\n",
              "      <td>0.674490</td>\n",
              "      <td>0.641903</td>\n",
              "      <td>0.036319</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.222959</td>\n",
              "      <td>0.016356</td>\n",
              "      <td>0.083863</td>\n",
              "      <td>0.025677</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'elastic_net__alpha': 10, 'elastic_net__l1_ra...</td>\n",
              "      <td>0.679356</td>\n",
              "      <td>0.759111</td>\n",
              "      <td>0.697470</td>\n",
              "      <td>0.654039</td>\n",
              "      <td>0.742257</td>\n",
              "      <td>0.706446</td>\n",
              "      <td>0.039030</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.240689</td>\n",
              "      <td>0.047562</td>\n",
              "      <td>0.069606</td>\n",
              "      <td>0.008810</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.8</td>\n",
              "      <td>{'elastic_net__alpha': 10, 'elastic_net__l1_ra...</td>\n",
              "      <td>0.767995</td>\n",
              "      <td>0.834319</td>\n",
              "      <td>0.753485</td>\n",
              "      <td>0.709800</td>\n",
              "      <td>0.817294</td>\n",
              "      <td>0.776579</td>\n",
              "      <td>0.044851</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.174732</td>\n",
              "      <td>0.514390</td>\n",
              "      <td>0.078910</td>\n",
              "      <td>0.006184</td>\n",
              "      <td>10.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'elastic_net__alpha': 10, 'elastic_net__l1_ra...</td>\n",
              "      <td>0.900776</td>\n",
              "      <td>0.915067</td>\n",
              "      <td>0.801420</td>\n",
              "      <td>0.776649</td>\n",
              "      <td>0.909250</td>\n",
              "      <td>0.860632</td>\n",
              "      <td>0.059157</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.853949</td>\n",
              "      <td>0.100512</td>\n",
              "      <td>0.064746</td>\n",
              "      <td>0.022515</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'elastic_net__alpha': 1, 'elastic_net__l1_rat...</td>\n",
              "      <td>0.819310</td>\n",
              "      <td>0.873470</td>\n",
              "      <td>0.775538</td>\n",
              "      <td>0.734519</td>\n",
              "      <td>0.857822</td>\n",
              "      <td>0.812132</td>\n",
              "      <td>0.051506</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.325946</td>\n",
              "      <td>0.071868</td>\n",
              "      <td>0.078156</td>\n",
              "      <td>0.012691</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>{'elastic_net__alpha': 1, 'elastic_net__l1_rat...</td>\n",
              "      <td>0.830470</td>\n",
              "      <td>0.881659</td>\n",
              "      <td>0.778866</td>\n",
              "      <td>0.739074</td>\n",
              "      <td>0.866618</td>\n",
              "      <td>0.819337</td>\n",
              "      <td>0.053523</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.366082</td>\n",
              "      <td>0.017626</td>\n",
              "      <td>0.080018</td>\n",
              "      <td>0.008366</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.4</td>\n",
              "      <td>{'elastic_net__alpha': 1, 'elastic_net__l1_rat...</td>\n",
              "      <td>0.842222</td>\n",
              "      <td>0.890269</td>\n",
              "      <td>0.781719</td>\n",
              "      <td>0.743712</td>\n",
              "      <td>0.876022</td>\n",
              "      <td>0.826789</td>\n",
              "      <td>0.055902</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.449935</td>\n",
              "      <td>0.091027</td>\n",
              "      <td>0.076855</td>\n",
              "      <td>0.017675</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'elastic_net__alpha': 1, 'elastic_net__l1_rat...</td>\n",
              "      <td>0.854984</td>\n",
              "      <td>0.899709</td>\n",
              "      <td>0.784092</td>\n",
              "      <td>0.748899</td>\n",
              "      <td>0.886498</td>\n",
              "      <td>0.834836</td>\n",
              "      <td>0.058726</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.466733</td>\n",
              "      <td>0.110328</td>\n",
              "      <td>0.080434</td>\n",
              "      <td>0.020014</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.8</td>\n",
              "      <td>{'elastic_net__alpha': 1, 'elastic_net__l1_rat...</td>\n",
              "      <td>0.869985</td>\n",
              "      <td>0.910922</td>\n",
              "      <td>0.786466</td>\n",
              "      <td>0.756417</td>\n",
              "      <td>0.899221</td>\n",
              "      <td>0.844602</td>\n",
              "      <td>0.061939</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3.058103</td>\n",
              "      <td>0.697691</td>\n",
              "      <td>0.084058</td>\n",
              "      <td>0.021421</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'elastic_net__alpha': 1, 'elastic_net__l1_rat...</td>\n",
              "      <td>0.897744</td>\n",
              "      <td>0.910938</td>\n",
              "      <td>0.796918</td>\n",
              "      <td>0.774262</td>\n",
              "      <td>0.905899</td>\n",
              "      <td>0.857152</td>\n",
              "      <td>0.059018</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>4.215102</td>\n",
              "      <td>0.218552</td>\n",
              "      <td>0.079678</td>\n",
              "      <td>0.022565</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'elastic_net__alpha': 0.1, 'elastic_net__l1_r...</td>\n",
              "      <td>0.879850</td>\n",
              "      <td>0.917863</td>\n",
              "      <td>0.789117</td>\n",
              "      <td>0.763703</td>\n",
              "      <td>0.907615</td>\n",
              "      <td>0.851630</td>\n",
              "      <td>0.063177</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.679451</td>\n",
              "      <td>0.092620</td>\n",
              "      <td>0.092877</td>\n",
              "      <td>0.015203</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.2</td>\n",
              "      <td>{'elastic_net__alpha': 0.1, 'elastic_net__l1_r...</td>\n",
              "      <td>0.882328</td>\n",
              "      <td>0.919377</td>\n",
              "      <td>0.790188</td>\n",
              "      <td>0.766053</td>\n",
              "      <td>0.909625</td>\n",
              "      <td>0.853514</td>\n",
              "      <td>0.063208</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.699318</td>\n",
              "      <td>0.182625</td>\n",
              "      <td>0.122588</td>\n",
              "      <td>0.038982</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.4</td>\n",
              "      <td>{'elastic_net__alpha': 0.1, 'elastic_net__l1_r...</td>\n",
              "      <td>0.885159</td>\n",
              "      <td>0.920882</td>\n",
              "      <td>0.791710</td>\n",
              "      <td>0.769058</td>\n",
              "      <td>0.911782</td>\n",
              "      <td>0.855718</td>\n",
              "      <td>0.063029</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.717790</td>\n",
              "      <td>0.128915</td>\n",
              "      <td>0.073360</td>\n",
              "      <td>0.011625</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'elastic_net__alpha': 0.1, 'elastic_net__l1_r...</td>\n",
              "      <td>0.888569</td>\n",
              "      <td>0.922246</td>\n",
              "      <td>0.794001</td>\n",
              "      <td>0.773162</td>\n",
              "      <td>0.914040</td>\n",
              "      <td>0.858404</td>\n",
              "      <td>0.062442</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.925372</td>\n",
              "      <td>0.027346</td>\n",
              "      <td>0.071499</td>\n",
              "      <td>0.016748</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.8</td>\n",
              "      <td>{'elastic_net__alpha': 0.1, 'elastic_net__l1_r...</td>\n",
              "      <td>0.893079</td>\n",
              "      <td>0.922926</td>\n",
              "      <td>0.797659</td>\n",
              "      <td>0.779403</td>\n",
              "      <td>0.915982</td>\n",
              "      <td>0.861810</td>\n",
              "      <td>0.060916</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>9.406198</td>\n",
              "      <td>0.861054</td>\n",
              "      <td>0.147686</td>\n",
              "      <td>0.037843</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'elastic_net__alpha': 0.1, 'elastic_net__l1_r...</td>\n",
              "      <td>0.897258</td>\n",
              "      <td>0.910451</td>\n",
              "      <td>0.795951</td>\n",
              "      <td>0.774072</td>\n",
              "      <td>0.905360</td>\n",
              "      <td>0.856618</td>\n",
              "      <td>0.059025</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>7.723573</td>\n",
              "      <td>2.494783</td>\n",
              "      <td>0.088235</td>\n",
              "      <td>0.020642</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'elastic_net__alpha': 0.01, 'elastic_net__l1_...</td>\n",
              "      <td>0.896040</td>\n",
              "      <td>0.922238</td>\n",
              "      <td>0.800041</td>\n",
              "      <td>0.784050</td>\n",
              "      <td>0.916064</td>\n",
              "      <td>0.863687</td>\n",
              "      <td>0.059349</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3.174350</td>\n",
              "      <td>0.119054</td>\n",
              "      <td>0.094142</td>\n",
              "      <td>0.016193</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.2</td>\n",
              "      <td>{'elastic_net__alpha': 0.01, 'elastic_net__l1_...</td>\n",
              "      <td>0.896681</td>\n",
              "      <td>0.921867</td>\n",
              "      <td>0.800427</td>\n",
              "      <td>0.785142</td>\n",
              "      <td>0.915852</td>\n",
              "      <td>0.863994</td>\n",
              "      <td>0.058933</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>4.098570</td>\n",
              "      <td>0.530836</td>\n",
              "      <td>0.138491</td>\n",
              "      <td>0.033418</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.4</td>\n",
              "      <td>{'elastic_net__alpha': 0.01, 'elastic_net__l1_...</td>\n",
              "      <td>0.897310</td>\n",
              "      <td>0.921353</td>\n",
              "      <td>0.800648</td>\n",
              "      <td>0.786264</td>\n",
              "      <td>0.915497</td>\n",
              "      <td>0.864214</td>\n",
              "      <td>0.058493</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>5.358223</td>\n",
              "      <td>0.416490</td>\n",
              "      <td>0.157631</td>\n",
              "      <td>0.041195</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'elastic_net__alpha': 0.01, 'elastic_net__l1_...</td>\n",
              "      <td>0.897874</td>\n",
              "      <td>0.920638</td>\n",
              "      <td>0.800485</td>\n",
              "      <td>0.787338</td>\n",
              "      <td>0.914966</td>\n",
              "      <td>0.864260</td>\n",
              "      <td>0.058075</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>5.565087</td>\n",
              "      <td>0.245928</td>\n",
              "      <td>0.075465</td>\n",
              "      <td>0.021942</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.8</td>\n",
              "      <td>{'elastic_net__alpha': 0.01, 'elastic_net__l1_...</td>\n",
              "      <td>0.898223</td>\n",
              "      <td>0.919618</td>\n",
              "      <td>0.799263</td>\n",
              "      <td>0.788001</td>\n",
              "      <td>0.914333</td>\n",
              "      <td>0.863888</td>\n",
              "      <td>0.057904</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3.707878</td>\n",
              "      <td>1.127287</td>\n",
              "      <td>0.054955</td>\n",
              "      <td>0.017130</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'elastic_net__alpha': 0.01, 'elastic_net__l1_...</td>\n",
              "      <td>0.897206</td>\n",
              "      <td>0.910401</td>\n",
              "      <td>0.790859</td>\n",
              "      <td>0.774060</td>\n",
              "      <td>0.905502</td>\n",
              "      <td>0.855606</td>\n",
              "      <td>0.060107</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  mean_score_time  ...  mean_test_score  std_test_score  rank_test_score\n",
              "0        6.099353      0.184961         0.078556  ...         0.099929        0.016126               30\n",
              "1        0.735556      0.090153         0.098475  ...         0.123748        0.017145               29\n",
              "2        0.482855      0.212672         0.126260  ...         0.160798        0.018745               28\n",
              "3        0.441589      0.199112         0.113518  ...         0.226225        0.021554               27\n",
              "4        0.218410      0.028490         0.084411  ...         0.371536        0.027382               26\n",
              "5        0.985579      0.132381         0.072317  ...         0.866931        0.060069                1\n",
              "6        3.819300      0.209461         0.068532  ...         0.536276        0.032954               25\n",
              "7        0.208285      0.020300         0.117551  ...         0.585258        0.034473               24\n",
              "8        0.255570      0.058557         0.070383  ...         0.641903        0.036319               23\n",
              "9        0.222959      0.016356         0.083863  ...         0.706446        0.039030               22\n",
              "10       0.240689      0.047562         0.069606  ...         0.776579        0.044851               21\n",
              "11       1.174732      0.514390         0.078910  ...         0.860632        0.059157                8\n",
              "12       3.853949      0.100512         0.064746  ...         0.812132        0.051506               20\n",
              "13       0.325946      0.071868         0.078156  ...         0.819337        0.053523               19\n",
              "14       0.366082      0.017626         0.080018  ...         0.826789        0.055902               18\n",
              "15       0.449935      0.091027         0.076855  ...         0.834836        0.058726               17\n",
              "16       0.466733      0.110328         0.080434  ...         0.844602        0.061939               16\n",
              "17       3.058103      0.697691         0.084058  ...         0.857152        0.059018               10\n",
              "18       4.215102      0.218552         0.079678  ...         0.851630        0.063177               15\n",
              "19       0.679451      0.092620         0.092877  ...         0.853514        0.063208               14\n",
              "20       0.699318      0.182625         0.122588  ...         0.855718        0.063029               12\n",
              "21       0.717790      0.128915         0.073360  ...         0.858404        0.062442                9\n",
              "22       0.925372      0.027346         0.071499  ...         0.861810        0.060916                7\n",
              "23       9.406198      0.861054         0.147686  ...         0.856618        0.059025               11\n",
              "24       7.723573      2.494783         0.088235  ...         0.863687        0.059349                6\n",
              "25       3.174350      0.119054         0.094142  ...         0.863994        0.058933                4\n",
              "26       4.098570      0.530836         0.138491  ...         0.864214        0.058493                3\n",
              "27       5.358223      0.416490         0.157631  ...         0.864260        0.058075                2\n",
              "28       5.565087      0.245928         0.075465  ...         0.863888        0.057904                5\n",
              "29       3.707878      1.127287         0.054955  ...         0.855606        0.060107               13\n",
              "\n",
              "[30 rows x 15 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cv_results_elastic = pd.DataFrame(gscv_fitted_elastic.cv_results_)\n",
        "\n",
        "df_cv_results_elastic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g1zfb9p9k1c",
        "outputId": "c99a259b-e0b5-4e47-a844-ca5d9446d442"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'elastic_net__alpha': 100, 'elastic_net__l1_ratio': np.float64(1.0)}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gscv_fitted_elastic.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9NQ3mKO9x5g",
        "outputId": "f4bf2f6f-5007-43f3-befa-6112051fcc20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.8669311075511448)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gscv_fitted_elastic.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qaeMII4T91YR",
        "outputId": "6e588e24-750f-4685-e584-b1a283b075e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lr</th>\n",
              "      <th>ridge</th>\n",
              "      <th>lasso</th>\n",
              "      <th>elastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-4648.554959</td>\n",
              "      <td>-4906.494598</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1546.687999</td>\n",
              "      <td>2346.943135</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-7516.051924</td>\n",
              "      <td>-1229.177404</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7867.442231</td>\n",
              "      <td>4620.911891</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3774.440540</td>\n",
              "      <td>2204.285000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>2670.612233</td>\n",
              "      <td>3104.701760</td>\n",
              "      <td>2829.886060</td>\n",
              "      <td>2829.886060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>2776.215267</td>\n",
              "      <td>489.258612</td>\n",
              "      <td>791.915349</td>\n",
              "      <td>791.915349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>-5139.727420</td>\n",
              "      <td>-4135.488058</td>\n",
              "      <td>-4328.443776</td>\n",
              "      <td>-4328.443776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>-774.812417</td>\n",
              "      <td>-638.220273</td>\n",
              "      <td>-576.052919</td>\n",
              "      <td>-576.052919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>-613.063064</td>\n",
              "      <td>-977.427542</td>\n",
              "      <td>-767.372632</td>\n",
              "      <td>-767.372632</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>254 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              lr        ridge        lasso      elastic\n",
              "0   -4648.554959 -4906.494598    -0.000000    -0.000000\n",
              "1    1546.687999  2346.943135     0.000000     0.000000\n",
              "2   -7516.051924 -1229.177404    -0.000000    -0.000000\n",
              "3    7867.442231  4620.911891     0.000000     0.000000\n",
              "4    3774.440540  2204.285000     0.000000     0.000000\n",
              "..           ...          ...          ...          ...\n",
              "249  2670.612233  3104.701760  2829.886060  2829.886060\n",
              "250  2776.215267   489.258612   791.915349   791.915349\n",
              "251 -5139.727420 -4135.488058 -4328.443776 -4328.443776\n",
              "252  -774.812417  -638.220273  -576.052919  -576.052919\n",
              "253  -613.063064  -977.427542  -767.372632  -767.372632\n",
              "\n",
              "[254 rows x 4 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elastic_coef = gscv_fitted_elastic.best_estimator_.named_steps['elastic_net'].coef_\n",
        "coef_df['elastic'] = elastic_coef\n",
        "coef_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUs-6nl3FVTI"
      },
      "source": [
        "Analysis: The table shows coefficients from Linear, Ridge, Lasso, and Elastic Net models. Since the Elastic Net’s L1 ratio is 1.0, the Ridge part becomes zero, so it behaves just like Lasso. This means it sets many coefficients to zero and removes less important features."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
